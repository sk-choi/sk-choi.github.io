---
title : "ollama 설치(ubuntu in windows)"
date : 2024-05-22 00:14:30 +/-TTTT
categories : 
- AI
tags : 
- [인공지능] #소문자만 가능
published : true
#permalink : categories/internship

#header :
  #teaser : 

toc: true
toc_sticky: true
sidebar:
    nav: "sidebar-category"
---

![img](https://ollama.com/public/assets/c889cc0d-cb83-4c46-a98e-0d0e273151b9/42f6b28d-9117-48cd-ac0d-44baaf5c178e.png)

### 참고 링크 모음

**Ollama 설치**  
[참고링크1](https://velog.io/@anstmdwn34/Ollama-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC)

[참고링크2](https://fornewchallenge.tistory.com/entry/Ollama%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8-%EC%9B%B9-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4-%EB%A7%8C%EB%93%A4%EA%B8%B0-Mistral-7B%EC%99%80%EC%9D%98-%EB%8C%80%ED%99%94)

**WSL 업데이트**  
[참고링크3](https://hacktiming.tistory.com/15)

* * *

### Ollama란?

Ollama는 페이스북에서 만든 생성형 인공지능 모델이며 local 기반에서 작동할 수 있는 특징을 가지고 있다. Chat-gpt 사용 시 외부 정보 노출이 우려될 때 사용할 수 있다.

llama의 경우 윈도우 버전의 경우엔 아직 preview 버전이라서 안정적인 실행을 하기 위해서 window의 가상환경에 ubuntu를 설치해서 ollama를 다운 받았다.
아래 코드를 우분투에서 실행하면 ollama를 다운받을 수 있다.

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

* * *

### 여러 시행 착오

로컬 기반에서 작동할 수 있는 생성형 인공지능 모델이라고 하지만, 아무래도 인공지능은 인공지능인 만큼 굉장히 많은 저장공간을 필요로 한다.

7년된 내 노트북은 256GB라는 저장공간을 가지고 있기 때문에 한번에 4GB정도 되는 모델을 다운받기엔 큰 부담인 것 같다.

그리고 인공지능인 만큼 연산을 위해서는 GPU가 필요한데, GPU없이 CPU만을 사용해서 대답을 출력하려면 완전히 출력하는데

5분 정도 걸리는 것 같다(intel core i5 7세대 기준). 아무튼 GPU가 필요하다~~!

tinyllama라는 일종의 경량화 모델이 있긴 하지만, 이건 대답 속도는 llama3에 비해서 빠르지만 정확도가 낮은 것 같았다.

그래도 로컬 기반에서 GPT 같은 모델을 굴리고 싶다면 설치해 볼만 하다.